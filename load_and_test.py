#!/usr/bin/env python3
"""
Simple script to load and test the GPT-OSS-20B model.
Uses the production-ready implementation from evennewerfile.py
"""

import sys
import os
from pathlib import Path

# Check if we need to install dependencies
try:
    import safetensors
except ImportError:
    print("Installing safetensors...")
    import subprocess
    subprocess.check_call([sys.executable, "-m", "pip", "install", "safetensors", "-q"])

# Import the complete implementation
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from evennewerfile import load_model, GPTOSSConfig

def main():
    model_path = "gpt-oss-20b"
    
    print(f"üìÇ Loading GPT-OSS-20B model from: {model_path}")
    print("=" * 60)
    
    try:
        # Load the model
        model, config = load_model(model_path)
        
        print("‚úÖ Model loaded successfully!")
        print(f"\nüìä Model Configuration:")
        print(f"  ‚Ä¢ Hidden size: {config.hidden_size}")
        print(f"  ‚Ä¢ Layers: {config.num_hidden_layers}")
        print(f"  ‚Ä¢ Attention heads: {config.num_attention_heads}")
        print(f"  ‚Ä¢ KV heads: {config.num_key_value_heads}")
        print(f"  ‚Ä¢ Vocab size: {config.vocab_size:,}")
        print(f"  ‚Ä¢ Max positions: {config.max_position_embeddings:,}")
        print(f"  ‚Ä¢ Experts: {config.num_local_experts}")
        print(f"  ‚Ä¢ Active experts: {config.num_experts_per_tok}")
        print(f"  ‚Ä¢ Quantization: {config.quantization_method}")
        
        # Quick test with dummy input
        print(f"\nüß™ Running quick inference test...")
        import numpy as np
        test_input = np.array([[1, 2, 3, 4, 5]], dtype=np.int32)
        
        try:
            output = model(test_input)
            print(f"‚úÖ Inference successful!")
            print(f"  ‚Ä¢ Input shape: {test_input.shape}")
            print(f"  ‚Ä¢ Output shape: {output.shape}")
            print(f"  ‚Ä¢ Output dtype: {output.dtype}")
            
            # Check output validity
            if np.isfinite(output).all():
                print(f"  ‚Ä¢ Output values are finite ‚úì")
            else:
                print(f"  ‚Ä¢ Warning: Output contains NaN or Inf values")
                
        except Exception as e:
            print(f"‚ùå Inference failed: {e}")
            
        print("\n" + "=" * 60)
        print("üéâ Model is ready for use!")
        print("\nNext steps:")
        print("  1. Load proper tokenizer for text processing")
        print("  2. Implement generation/sampling strategies")
        print("  3. Run comprehensive validation tests")
        
    except Exception as e:
        print(f"‚ùå Error loading model: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()